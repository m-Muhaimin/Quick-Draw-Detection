{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f693553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43214/43214 [==============================] - 762s 18ms/step - loss: 0.3318 - accuracy: 0.8921 - val_loss: 0.9044 - val_accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "43214/43214 [==============================] - 826s 19ms/step - loss: 0.2582 - accuracy: 0.9151 - val_loss: 0.9987 - val_accuracy: 0.6615\n",
      "Epoch 3/10\n",
      "43214/43214 [==============================] - 736s 17ms/step - loss: 0.2415 - accuracy: 0.9202 - val_loss: 1.1302 - val_accuracy: 0.5968\n",
      "Epoch 4/10\n",
      "43214/43214 [==============================] - 797s 18ms/step - loss: 0.2322 - accuracy: 0.9234 - val_loss: 1.1608 - val_accuracy: 0.5984\n",
      "Epoch 5/10\n",
      "43214/43214 [==============================] - 754s 17ms/step - loss: 0.2261 - accuracy: 0.9251 - val_loss: 1.0247 - val_accuracy: 0.6448\n",
      "Epoch 6/10\n",
      "43214/43214 [==============================] - 723s 17ms/step - loss: 0.2217 - accuracy: 0.9265 - val_loss: 0.7927 - val_accuracy: 0.7181\n",
      "Epoch 7/10\n",
      "43214/43214 [==============================] - 719s 17ms/step - loss: 0.2180 - accuracy: 0.9279 - val_loss: 1.0371 - val_accuracy: 0.6592\n",
      "Epoch 8/10\n",
      "43214/43214 [==============================] - 919s 21ms/step - loss: 0.2149 - accuracy: 0.9288 - val_loss: 1.1379 - val_accuracy: 0.6081\n",
      "Epoch 9/10\n",
      "43214/43214 [==============================] - 1205s 28ms/step - loss: 0.2128 - accuracy: 0.9295 - val_loss: 1.0958 - val_accuracy: 0.6313\n",
      "Epoch 10/10\n",
      "43214/43214 [==============================] - 767s 18ms/step - loss: 0.2101 - accuracy: 0.9301 - val_loss: 0.6988 - val_accuracy: 0.7683\n",
      "4802/4802 [==============================] - 25s 5ms/step - loss: 0.6988 - accuracy: 0.7683\n",
      "Test accuracy: 0.7683030962944031\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Evaluation Results:\n",
      "Image 1: True Label = pig, Predicted Label = pig\n",
      "Image 2: True Label = pig, Predicted Label = pig\n",
      "Image 3: True Label = pig, Predicted Label = pig\n",
      "Image 4: True Label = pig, Predicted Label = pig\n",
      "Image 5: True Label = pig, Predicted Label = pig\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Directory containing the dataset files\n",
    "data_directory = 'data/cnn_dataset2'\n",
    "\n",
    "# List of category names\n",
    "categories = ['ambulance', 'apple', 'bear', 'bicycle', 'bird', 'bus', 'cat', 'foot', 'owl', 'pig']\n",
    "\n",
    "# Load the dataset for each category\n",
    "dataset = []\n",
    "labels = []\n",
    "for i, category in enumerate(categories):\n",
    "    category_file = os.path.join(data_directory, f\"{category}.npy\")\n",
    "    category_data = np.load(category_file, allow_pickle=True)\n",
    "    dataset.extend(category_data)\n",
    "    labels.extend([i] * len(category_data))  # Assign label for the category\n",
    "\n",
    "# Convert the dataset and labels to numpy arrays\n",
    "dataset = np.array(dataset)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize the pixel values of images between 0 and 1\n",
    "dataset = dataset / 255.0\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "split_index = int(0.9 * len(dataset))  # Split at 90% for training\n",
    "train_images = dataset[:split_index]\n",
    "train_labels = labels[:split_index]\n",
    "test_images = dataset[split_index:]\n",
    "test_labels = labels[split_index:]\n",
    "\n",
    "# Reshape the images for compatibility with Conv2D layer\n",
    "train_images = np.reshape(train_images, (train_images.shape[0], 28, 28, 1))\n",
    "test_images = np.reshape(test_images, (test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Select random images from each category for further evaluation\n",
    "num_images_per_category = 5\n",
    "category_indices = np.unique(test_labels)\n",
    "random_indices = []\n",
    "\n",
    "for category_index in category_indices:\n",
    "    indices = np.where(test_labels == category_index)[0]\n",
    "    random_indices.extend(np.random.choice(indices, size=num_images_per_category, replace=False))\n",
    "\n",
    "evaluation_images = test_images[random_indices]\n",
    "evaluation_labels = test_labels[random_indices]\n",
    "\n",
    "# Predict labels for evaluation images\n",
    "predictions = model.predict(evaluation_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print the true and predicted labels for evaluation images\n",
    "print(\"Evaluation Results:\")\n",
    "for i in range(len(evaluation_images)):\n",
    "    true_label = categories[evaluation_labels[i]]\n",
    "    predicted_label = categories[predicted_labels[i]]\n",
    "    print(f\"Image {i+1}: True Label = {true_label}, Predicted Label = {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efc9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as an h5 file\n",
    "model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed647bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
